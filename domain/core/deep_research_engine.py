"""
Deep Research Engine - –ú–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–π —Ä–µ–∂–∏–º —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

–°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
—Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞—â–µ–Ω–∏–π –∫ LLM –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω—ã—Ö –∏ —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.

–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- –ú–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º –∏ –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π
- Real-time –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ö–æ–¥–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
"""

import asyncio
import logging
import uuid
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, AsyncGenerator, Dict, List, Optional
from uuid import uuid4

from domain.core.llm_generation_service import LLMGenerationService
from domain.integration.enhanced_vector_search_service import \
    get_enhanced_vector_search_service

logger = logging.getLogger(__name__)


class ResearchStepType(Enum):
    """–¢–∏–ø—ã —à–∞–≥–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""

    INITIAL_ANALYSIS = "initial_analysis"
    CONTEXT_GATHERING = "context_gathering"
    DEEP_ANALYSIS = "deep_analysis"
    SYNTHESIS = "synthesis"
    VALIDATION = "validation"
    FINAL_SUMMARY = "final_summary"


class ResearchStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""

    CREATED = "created"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class StepStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —à–∞–≥–æ–≤"""

    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


@dataclass
class ResearchStep:
    """–û—Ç–¥–µ–ª—å–Ω—ã–π —à–∞–≥ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""

    step_id: str = field(default_factory=lambda: str(uuid4()))
    step_type: ResearchStepType = ResearchStepType.INITIAL_ANALYSIS
    status: StepStatus = StepStatus.PENDING
    title: str = ""
    description: str = ""
    query: str = ""
    result: str = ""
    sources: List[Dict[str, Any]] = field(default_factory=list)
    confidence: float = 0.0
    duration: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None
    error_message: str = ""
    next_steps: List[str] = field(default_factory=list)


@dataclass
class ResearchSession:
    """–°–µ—Å—Å–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""

    session_id: str = field(default_factory=lambda: str(uuid4()))
    user_id: str = ""
    original_query: str = ""
    research_goal: str = ""
    status: ResearchStatus = ResearchStatus.CREATED
    steps: List[ResearchStep] = field(default_factory=list)
    current_step: int = 0
    max_steps: int = 7
    final_result: str = ""
    total_sources: int = 0
    overall_confidence: float = 0.0
    duration: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class DeepResearchEngine:
    """–î–≤–∏–∂–æ–∫ —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""

    def __init__(self):
        self.llm_service = LLMGenerationService()
        self.active_sessions: Dict[str, ResearchSession] = {}

        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–≤–∏–∂–∫–∞
        self.metrics = {
            "total_sessions": 0,
            "completed_sessions": 0,
            "average_steps": 0.0,
            "average_duration": 0.0,
            "success_rate": 0.0,
        }

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.config = {
            "max_concurrent_sessions": 10,
            "default_max_steps": 7,
            "step_timeout": 60,  # —Å–µ–∫—É–Ω–¥—ã
            "min_confidence_threshold": 0.6,
            "enable_adaptive_planning": True,
        }

    async def start_research(
        self, query: str, user_id: str = "", max_steps: int = None
    ) -> ResearchSession:
        """–ù–∞—á–∞—Ç—å –Ω–æ–≤–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ"""
        if len(self.active_sessions) >= self.config["max_concurrent_sessions"]:
            raise Exception("–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π")

        session = ResearchSession(
            user_id=user_id,
            original_query=query,
            research_goal=await self._extract_research_goal(query),
            max_steps=max_steps or self.config["default_max_steps"],
        )

        self.active_sessions[session.session_id] = session
        self.metrics["total_sessions"] += 1

        logger.info(f"üî¨ –ù–∞—á–∞—Ç–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: {session.session_id}")
        return session

    async def execute_research(
        self, session_id: str
    ) -> AsyncGenerator[ResearchStep, None]:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        session = self.active_sessions.get(session_id)
        if not session:
            raise ValueError(f"–°–µ—Å—Å–∏—è {session_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

        session.status = ResearchStatus.IN_PROGRESS
        start_time = datetime.now()

        try:
            # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —à–∞–≥–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            planned_steps = await self._plan_research_steps(session)
            session.steps = planned_steps

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —à–∞–≥–æ–≤
            for i, step in enumerate(session.steps):
                if i >= session.max_steps:
                    break

                session.current_step = i
                step.status = StepStatus.RUNNING

                logger.info(f"üîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —à–∞–≥ {i+1}: {step.title}")

                try:
                    await self._execute_step(step, session)
                    step.status = StepStatus.COMPLETED
                    step.completed_at = datetime.now()

                    yield step

                    # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
                    if (
                        self.config["enable_adaptive_planning"]
                        and i < len(session.steps) - 1
                    ):
                        await self._adapt_next_steps(session, i)

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏
                    if await self._is_research_complete(session, step):
                        logger.info(
                            "‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–æ—Å—Ä–æ—á–Ω–æ - —Ü–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞"
                        )
                        break

                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —à–∞–≥–∞ {i+1}: {e}")
                    step.status = StepStatus.FAILED
                    step.error_message = str(e)
                    yield step
                    continue

            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            session.final_result = await self._synthesize_final_result(session)
            session.status = ResearchStatus.COMPLETED
            session.completed_at = datetime.now()
            session.duration = (datetime.now() - start_time).total_seconds()

            self._update_metrics(session)

            logger.info(f"‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {session.session_id}")

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {e}")
            session.status = ResearchStatus.FAILED
            session.completed_at = datetime.now()
            raise

    async def _extract_research_goal(self, query: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏–∑ –∑–∞–ø—Ä–æ—Å–∞"""
        system_prompt = """
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —á–µ—Ç–∫—É—é —Ü–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.
        –¶–µ–ª—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π, –∏–∑–º–µ—Ä–∏–º–æ–π –∏ –¥–æ—Å—Ç–∏–∂–∏–º–æ–π –≤ —Ä–∞–º–∫–∞—Ö 5-7 —à–∞–≥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞.
        
        –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º, –Ω–∞—á–∏–Ω–∞—é—â–∏–º—Å—è —Å –≥–ª–∞–≥–æ–ª–∞ –¥–µ–π—Å—Ç–≤–∏—è.
        """

        try:
            response = await self.llm_service.generate_response(
                query=query, system_prompt=system_prompt, max_tokens=150
            )
            return response.strip()
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ü–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {e}")
            return f"–ü—Ä–æ–≤–µ—Å—Ç–∏ —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: {query}"

    async def _plan_research_steps(
        self, session: ResearchSession
    ) -> List[ResearchStep]:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —à–∞–≥–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        planning_prompt = f"""
        –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {session.original_query}
        –¶–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {session.research_goal}
        –ú–∞–∫—Å–∏–º—É–º —à–∞–≥–æ–≤: {session.max_steps}
        
        –°–ø–ª–∞–Ω–∏—Ä—É–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —à–∞–≥–æ–≤ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏.
        –ö–∞–∂–¥—ã–π —à–∞–≥ –¥–æ–ª–∂–µ–Ω –ª–æ–≥–∏—á–µ—Å–∫–∏ —Å–ª–µ–¥–æ–≤–∞—Ç—å –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∏ –ø—Ä–∏–±–ª–∏–∂–∞—Ç—å –∫ —Ü–µ–ª–∏.
        
        –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã —à–∞–≥–æ–≤:
        1. initial_analysis - –ø–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        2. context_gathering - —Å–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        3. deep_analysis - —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤
        4. synthesis - —Å–∏–Ω—Ç–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        5. validation - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        6. final_summary - —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–æ–±—â–µ–Ω–∏–µ
        
        –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–ø–∏—Å–∫–∞ —à–∞–≥–æ–≤ —Å –ø–æ–ª—è–º–∏: title, description, step_type, query.
        """

        try:
            response = await self.llm_service.generate_response(
                query=planning_prompt,
                system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π. –°–æ–∑–¥–∞–≤–∞–π —á–µ—Ç–∫–∏–µ, –ª–æ–≥–∏—á–Ω—ã–µ –ø–ª–∞–Ω—ã.",
                max_tokens=800,
            )

            # –ü–∞—Ä—Å–∏–Ω–≥ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —à–∞–≥–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)
            steps = []
            step_types = [
                ResearchStepType.INITIAL_ANALYSIS,
                ResearchStepType.CONTEXT_GATHERING,
                ResearchStepType.DEEP_ANALYSIS,
                ResearchStepType.SYNTHESIS,
                ResearchStepType.VALIDATION,
                ResearchStepType.FINAL_SUMMARY,
            ]

            for i, step_type in enumerate(step_types[: session.max_steps]):
                step = ResearchStep(
                    step_type=step_type,
                    title=f"–®–∞–≥ {i+1}: {step_type.value.replace('_', ' ').title()}",
                    description=f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ {step_type.value} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {session.original_query}",
                    query=session.original_query,
                )
                steps.append(step)

            return steps

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —à–∞–≥–æ–≤: {e}")
            # –ë–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω
            return [
                ResearchStep(
                    step_type=ResearchStepType.INITIAL_ANALYSIS,
                    title="–ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
                    description="–ê–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞",
                    query=session.original_query,
                ),
                ResearchStep(
                    step_type=ResearchStepType.CONTEXT_GATHERING,
                    title="–°–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
                    description="–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                    query=session.original_query,
                ),
                ResearchStep(
                    step_type=ResearchStepType.FINAL_SUMMARY,
                    title="–§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–æ–±—â–µ–Ω–∏–µ",
                    description="–ü–æ–¥–≤–µ–¥–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
                    query=session.original_query,
                ),
            ]

    async def _execute_step(self, step: ResearchStep, session: ResearchSession):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —à–∞–≥–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        step_start = datetime.now()

        try:
            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            if step.step_type in [
                ResearchStepType.CONTEXT_GATHERING,
                ResearchStepType.DEEP_ANALYSIS,
            ]:
                search_service = await get_enhanced_vector_search_service()
                search_results = await search_service.enhanced_search(
                    query=step.query, limit=10, score_threshold=0.5
                )
                step.sources = [
                    {
                        "title": result.get("title", ""),
                        "content": result.get("content", "")[:500],
                        "source": result.get("source", ""),
                        "score": result.get("score", 0.0),
                    }
                    for result in search_results.get("results", [])
                ]

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —à–∞–≥–∞
            context = self._build_step_context(step, session)
            step_prompt = self._build_step_prompt(step, context)

            response = await self.llm_service.generate_response(
                query=step_prompt,
                system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –ü—Ä–æ–≤–æ–¥–∏ —Ç—â–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –¥–∞–≤–∞–π –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –≤—ã–≤–æ–¥—ã.",
                max_tokens=1000,
            )

            step.result = response
            step.confidence = self._calculate_step_confidence(step)
            step.duration = (datetime.now() - step_start).total_seconds()

            # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
            if step.step_type != ResearchStepType.FINAL_SUMMARY:
                step.next_steps = await self._suggest_next_steps(step, session)

            logger.info(
                f"‚úÖ –®–∞–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω: {step.title} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {step.confidence:.2f})"
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —à–∞–≥–∞ {step.title}: {e}")
            raise

    def _build_step_context(self, step: ResearchStep, session: ResearchSession) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è —à–∞–≥–∞"""
        context_parts = [
            f"–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {session.original_query}",
            f"–¶–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {session.research_goal}",
            f"–¢–µ–∫—É—â–∏–π —à–∞–≥: {step.title}",
        ]

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤
        completed_steps = [s for s in session.steps if s.status == StepStatus.COMPLETED]
        if completed_steps:
            context_parts.append("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —à–∞–≥–æ–≤:")
            for prev_step in completed_steps[-3:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —à–∞–≥–∞
                context_parts.append(
                    f"- {prev_step.title}: {prev_step.result[:200]}..."
                )

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if step.sources:
            context_parts.append("–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
            for source in step.sources[:3]:  # –¢–æ–ø-3 –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                context_parts.append(
                    f"- {source['title']}: {source['content'][:150]}..."
                )

        return "\n".join(context_parts)

    def _build_step_prompt(self, step: ResearchStep, context: str) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —à–∞–≥–∞"""
        step_instructions = {
            ResearchStepType.INITIAL_ANALYSIS: "–ü—Ä–æ–≤–µ–¥–∏ –ø–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞, –æ–ø—Ä–µ–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã –∏ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.",
            ResearchStepType.CONTEXT_GATHERING: "–°–æ–±–µ—Ä–∏ –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.",
            ResearchStepType.DEEP_ANALYSIS: "–ü—Ä–æ–≤–µ–¥–∏ —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.",
            ResearchStepType.SYNTHESIS: "–°–∏–Ω—Ç–µ–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –Ω–∞–π–¥–∏ —Å–≤—è–∑–∏ –∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏.",
            ResearchStepType.VALIDATION: "–ü—Ä–æ–≤–µ—Ä—å –∏ –≤–∞–ª–∏–¥–∏—Ä—É–π –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –æ—Ü–µ–Ω–∏ –∏—Ö –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å.",
            ResearchStepType.FINAL_SUMMARY: "–ü–æ–¥–≤–µ–¥–∏ –∏—Ç–æ–≥–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –¥–∞–π –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å.",
        }

        instruction = step_instructions.get(
            step.step_type, "–í—ã–ø–æ–ª–Ω–∏ –∞–Ω–∞–ª–∏–∑ –≤ —Ä–∞–º–∫–∞—Ö —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞."
        )

        return f"""
{instruction}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç–≤–µ—Ç—É:
- –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º
- –ò—Å–ø–æ–ª—å–∑—É–π –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
- –£–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- –§–æ—Ä–º—É–ª–∏—Ä—É–π —á–µ—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã
- –ü—Ä–µ–¥–ª–∞–≥–∞–π –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
"""

    def _calculate_step_confidence(self, step: ResearchStep) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö —à–∞–≥–∞"""
        confidence = 0.5  # –ë–∞–∑–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

        # –£—á–µ—Ç –Ω–∞–ª–∏—á–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if step.sources:
            confidence += 0.2
            # –£—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            avg_score = sum(s.get("score", 0) for s in step.sources) / len(step.sources)
            confidence += avg_score * 0.2

        # –£—á–µ—Ç –¥–ª–∏–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π = –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–π)
        if len(step.result) > 500:
            confidence += 0.1

        return min(1.0, confidence)

    async def _suggest_next_steps(
        self, step: ResearchStep, session: ResearchSession
    ) -> List[str]:
        """–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤"""
        try:
            prompt = f"""
            –ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞: {step.result[:300]}
            
            –ü—Ä–µ–¥–ª–æ–∂–∏ 2-3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.
            –ö–∞–∂–¥–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫ actionable –∑–∞–¥–∞—á–∞.
            """

            response = await self.llm_service.generate_response(
                query=prompt,
                system_prompt="–¢—ã —Å—Ç—Ä–∞—Ç–µ–≥ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –ü—Ä–µ–¥–ª–∞–≥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ, –≤—ã–ø–æ–ª–Ω–∏–º—ã–µ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏.",
                max_tokens=200,
            )

            # –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            suggestions = [
                s.strip()
                for s in response.split("\n")
                if s.strip() and not s.strip().startswith("-")
            ]
            return suggestions[:3]

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {e}")
            return [
                "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏",
            ]

    async def _adapt_next_steps(
        self, session: ResearchSession, current_step_index: int
    ):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤"""
        if current_step_index + 1 >= len(session.steps):
            return

        current_step = session.steps[current_step_index]

        # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è, –¥–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —à–∞–≥–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        if current_step.confidence < self.config["min_confidence_threshold"]:
            validation_step = ResearchStep(
                step_type=ResearchStepType.VALIDATION,
                title=f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è —à–∞–≥–∞ {current_step_index + 1}",
                description=f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {current_step.title}",
                query=current_step.query,
            )
            session.steps.insert(current_step_index + 1, validation_step)

    async def _is_research_complete(
        self, session: ResearchSession, last_step: ResearchStep
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è –∏ –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if last_step.confidence > 0.8 and len(last_step.result) > 200:
            return True

        # –ï—Å–ª–∏ –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –±–æ–ª–µ–µ 70% —à–∞–≥–æ–≤ —Å —Ö–æ—Ä–æ—à–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        completed_steps = [s for s in session.steps if s.status == StepStatus.COMPLETED]
        if len(completed_steps) >= session.max_steps * 0.7:
            avg_confidence = sum(s.confidence for s in completed_steps) / len(
                completed_steps
            )
            if avg_confidence > 0.7:
                return True

        return False

    async def _synthesize_final_result(self, session: ResearchSession) -> str:
        """–°–∏–Ω—Ç–µ–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        completed_steps = [s for s in session.steps if s.status == StepStatus.COMPLETED]

        if not completed_steps:
            return "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–µ –¥–∞–ª–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."

        # –°–±–æ—Ä –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        all_results = []
        all_sources = []

        for step in completed_steps:
            if step.result:
                all_results.append(f"{step.title}: {step.result}")
            all_sources.extend(step.sources)

        synthesis_prompt = f"""
        –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {session.original_query}
        –¶–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {session.research_goal}
        
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ —à–∞–≥–∞–º:
        {chr(10).join(all_results)}
        
        –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(all_sources)}
        
        –°–∏–Ω—Ç–µ–∑–∏—Ä—É–π –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
        –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å:
        - –ü–æ–ª–Ω—ã–º –∏ –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–º
        - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º
        - –°–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤—ã–≤–æ–¥—ã
        - –°—Å—ã–ª–∞—Ç—å—Å—è –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        """

        try:
            final_response = await self.llm_service.generate_response(
                query=synthesis_prompt,
                system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫. –°–æ–∑–¥–∞–≤–∞–π –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.",
                max_tokens=1500,
            )

            session.overall_confidence = sum(
                s.confidence for s in completed_steps
            ) / len(completed_steps)
            session.total_sources = len(all_sources)

            return final_response

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
            return f"–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(completed_steps)} —à–∞–≥–æ–≤, –Ω–∞–π–¥–µ–Ω–æ {len(all_sources)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤."

    def _update_metrics(self, session: ResearchSession):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–≤–∏–∂–∫–∞"""
        if session.status == ResearchStatus.COMPLETED:
            self.metrics["completed_sessions"] += 1

        # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        completed_sessions = self.metrics["completed_sessions"]
        if completed_sessions > 0:
            # –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
            total_steps = sum(
                len(s.steps)
                for s in self.active_sessions.values()
                if s.status == ResearchStatus.COMPLETED
            )
            self.metrics["average_steps"] = total_steps / completed_sessions

            # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            total_duration = sum(
                s.duration
                for s in self.active_sessions.values()
                if s.status == ResearchStatus.COMPLETED and s.duration > 0
            )
            self.metrics["average_duration"] = total_duration / completed_sessions

            # –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞
            self.metrics["success_rate"] = (
                completed_sessions / self.metrics["total_sessions"]
            )

    async def get_session_status(self, session_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–µ—Å—Å–∏–∏"""
        session = self.active_sessions.get(session_id)
        if not session:
            return None

        return {
            "session_id": session.session_id,
            "status": session.status.value,
            "current_step": session.current_step,
            "total_steps": len(session.steps),
            "progress": session.current_step / max(len(session.steps), 1),
            "duration": session.duration,
            "overall_confidence": session.overall_confidence,
            "total_sources": session.total_sources,
        }

    async def cancel_research(self, session_id: str) -> bool:
        """–û—Ç–º–µ–Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        session = self.active_sessions.get(session_id)
        if not session:
            return False

        session.status = ResearchStatus.CANCELLED
        session.completed_at = datetime.now()

        logger.info(f"üö´ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ: {session_id}")
        return True

    async def get_engine_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –¥–≤–∏–∂–∫–∞"""
        return {
            "engine_status": "active",
            "active_sessions": len(self.active_sessions),
            "metrics": self.metrics,
            "configuration": {
                "max_concurrent_sessions": self.config["max_concurrent_sessions"],
                "default_max_steps": self.config["default_max_steps"],
                "step_timeout": self.config["step_timeout"],
                "min_confidence_threshold": self.config["min_confidence_threshold"],
            },
            "last_updated": datetime.now().isoformat(),
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_deep_research_engine: Optional[DeepResearchEngine] = None


async def get_deep_research_engine() -> DeepResearchEngine:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –¥–≤–∏–∂–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π"""
    global _deep_research_engine
    if _deep_research_engine is None:
        _deep_research_engine = DeepResearchEngine()
        logger.info("üî¨ Deep Research Engine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    return _deep_research_engine
