#!/usr/bin/env python3
"""
üß™ TEST CLASSIFICATION AND REORGANIZATION SCRIPT
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç —Ç–µ—Å—Ç—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–ª–µ–¥—É—è Context7 best practices.

–¢–∏–ø—ã —Ç–µ—Å—Ç–æ–≤:
- unit: –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞, –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
- integration: –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –º–æ–¥—É–ª—è–º–∏, —Å –ë–î/API  
- e2e: –ø–æ–ª–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
- smoke: –±–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ "–∂–∏–≤–æ—Å—Ç–∏" –∫–ª—é—á–µ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
"""

import os
import re
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Set
import ast
import subprocess

class TestClassifier:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–µ—Å—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    
    def __init__(self, tests_dir: str = "tests"):
        self.tests_dir = Path(tests_dir)
        self.classification_patterns = {
            'unit': [
                r'unittest\.mock|from unittest\.mock import|mock\.',
                r'@pytest\.fixture.*scope.*function',
                r'AsyncMock|MagicMock|Mock\(\)',
                r'with.*patch\(',
                r'test.*utils?|test.*core|test.*async',
                r'TestClient.*mock',
                r'isolated.*test|pure.*logic'
            ],
            'integration': [
                r'psycopg2|sqlalchemy|database',
                r'redis|qdrant|elasticsearch',
                r'requests\.|httpx\.|aiohttp',
                r'docker|container',
                r'test.*integration|integration.*test',
                r'@pytest\.mark\.integration',
                r'real.*service|external.*api'
            ],
            'e2e': [
                r'TestClient\(app\)|FastAPI.*test',
                r'selenium|playwright|cypress',
                r'test.*workflow|full.*workflow',
                r'end.*to.*end|e2e',
                r'complete.*scenario|user.*journey',
                r'test.*comprehensive|comprehensive.*test',
                r'@pytest\.mark\.e2e'
            ],
            'smoke': [
                r'health.*check|test.*health',
                r'status.*endpoint|ping.*test',
                r'basic.*connectivity|simple.*test',
                r'smoke.*test|@pytest\.mark\.smoke',
                r'quick.*check|sanity.*test'
            ]
        }
        
        self.filename_patterns = {
            'unit': [
                r'test_.*utils?\.py$',
                r'test_.*core\.py$', 
                r'test_.*async.*patterns\.py$',
                r'test_.*models?\.py$',
                r'test_.*services?\.py$'
            ],
            'integration': [
                r'test_.*integration\.py$',
                r'test_.*qdrant.*\.py$',
                r'test_.*postgres.*\.py$',
                r'test_.*redis.*\.py$',
                r'test_.*database.*\.py$'
            ],
            'e2e': [
                r'test_.*e2e\.py$',
                r'test_.*comprehensive\.py$',
                r'test_.*workflow\.py$',
                r'test_.*end.*to.*end\.py$'
            ],
            'smoke': [
                r'test_.*health\.py$',
                r'test_.*smoke\.py$',
                r'test_.*quick\.py$',
                r'test_.*basic\.py$'
            ]
        }
        
    def analyze_file_content(self, file_path: Path) -> Tuple[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∏–ø —Ç–µ—Å—Ç–∞ —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é"""
        try:
            content = file_path.read_text(encoding='utf-8')
            scores = {test_type: 0 for test_type in self.classification_patterns}
            
            # –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            for test_type, patterns in self.classification_patterns.items():
                for pattern in patterns:
                    matches = len(re.findall(pattern, content, re.IGNORECASE | re.MULTILINE))
                    scores[test_type] += matches
            
            # –ê–Ω–∞–ª–∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            filename = file_path.name
            for test_type, patterns in self.filename_patterns.items():
                for pattern in patterns:
                    if re.match(pattern, filename, re.IGNORECASE):
                        scores[test_type] += 5  # –ò–º—è —Ñ–∞–π–ª–∞ –≤–∞–∂–Ω–µ–µ
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
            if 'testclient' in content.lower() and 'mock' in content.lower():
                scores['unit'] += 3
            elif 'testclient' in content.lower() and 'app' in content.lower():
                scores['e2e'] += 3
                
            if 'pytest.mark.asyncio' in content and 'database' not in content.lower():
                scores['unit'] += 2
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–∏–π —Ç–∏–ø
            best_type = max(scores, key=scores.get)
            confidence = scores[best_type] / max(sum(scores.values()), 1)
            
            return best_type, confidence
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {file_path}: {e}")
            return 'unit', 0.0
    
    def find_test_files(self) -> List[Path]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ tests/"""
        test_files = []
        for file_path in self.tests_dir.iterdir():
            if (file_path.is_file() and 
                file_path.name.startswith('test_') and 
                file_path.suffix == '.py' and
                file_path.name != 'conftest.py'):
                test_files.append(file_path)
        return test_files
    
    def classify_all_tests(self) -> Dict[str, List[Tuple[Path, float]]]:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã"""
        test_files = self.find_test_files()
        classified = {
            'unit': [],
            'integration': [],
            'e2e': [],
            'smoke': []
        }
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(test_files)} —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        for file_path in test_files:
            test_type, confidence = self.analyze_file_content(file_path)
            classified[test_type].append((file_path, confidence))
            print(f"üìÅ {file_path.name} ‚Üí {test_type} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
        
        return classified
    
    def create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        for test_type in ['unit', 'integration', 'e2e', 'smoke']:
            target_dir = self.tests_dir / test_type
            target_dir.mkdir(exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º __init__.py –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            init_file = target_dir / '__init__.py'
            if not init_file.exists():
                init_file.write_text('"""Tests for the AI Assistant project."""\n')
    
    def move_tests(self, classified: Dict[str, List[Tuple[Path, float]]], 
                   min_confidence: float = 0.1, dry_run: bool = False) -> Dict[str, int]:
        """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç —Ç–µ—Å—Ç—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        
        if dry_run:
            print("\nüß™ DRY RUN MODE - —Ñ–∞–π–ª—ã –ù–ï –±—É–¥—É—Ç –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã")
        
        moved_count = {'unit': 0, 'integration': 0, 'e2e': 0, 'smoke': 0}
        
        for test_type, files in classified.items():
            target_dir = self.tests_dir / test_type
            
            for file_path, confidence in files:
                if confidence < min_confidence:
                    print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {file_path.name} - –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ({confidence:.2f})")
                    continue
                
                target_path = target_dir / file_path.name
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã
                if target_path.exists():
                    print(f"‚ö†Ô∏è  –ö–æ–Ω—Ñ–ª–∏–∫—Ç: {target_path} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                    # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø –∏–º—è
                    counter = 1
                    while target_path.exists():
                        name_parts = file_path.stem, counter, file_path.suffix
                        target_path = target_dir / f"{name_parts[0]}_{name_parts[1]}{name_parts[2]}"
                        counter += 1
                
                if dry_run:
                    print(f"üìÅ [DRY] {file_path} ‚Üí {target_path}")
                else:
                    try:
                        shutil.move(str(file_path), str(target_path))
                        print(f"‚úÖ –ü–µ—Ä–µ–º–µ—â–µ–Ω: {file_path.name} ‚Üí {test_type}/")
                        moved_count[test_type] += 1
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è {file_path}: {e}")
        
        return moved_count
    
    def update_imports_in_moved_tests(self, moved_files: Dict[str, List[str]]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∏–º–ø–æ—Ä—Ç—ã –≤ –ø–µ—Ä–µ–º–µ—â–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–∞—Ö"""
        print("\nüîß –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤...")
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–æ–≤
        import_updates = [
            (r'from tests\.conftest import', r'from ..conftest import'),
            (r'from tests\.(.+) import', r'from ..\\1 import'),
            (r'import tests\.(.+)', r'import tests.\\1'),  # –û—Å—Ç–∞–≤–ª—è–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è tests.*
        ]
        
        for test_type, files in moved_files.items():
            for filename in files:
                file_path = self.tests_dir / test_type / filename
                if not file_path.exists():
                    continue
                
                try:
                    content = file_path.read_text(encoding='utf-8')
                    original_content = content
                    
                    for pattern, replacement in import_updates:
                        content = re.sub(pattern, replacement, content)
                    
                    if content != original_content:
                        file_path.write_text(content, encoding='utf-8')
                        print(f"üìù –û–±–Ω–æ–≤–ª–µ–Ω—ã –∏–º–ø–æ—Ä—Ç—ã –≤ {test_type}/{filename}")
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–æ–≤ –≤ {file_path}: {e}")
    
    def generate_summary_report(self, classified: Dict[str, List[Tuple[Path, float]]], 
                              moved_count: Dict[str, int]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        
        total_files = sum(len(files) for files in classified.values())
        total_moved = sum(moved_count.values())
        
        report = [
            "\n" + "="*60,
            "üìä –û–¢–ß–ï–¢ –û –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –ò –†–ï–û–†–ì–ê–ù–ò–ó–ê–¶–ò–ò –¢–ï–°–¢–û–í",
            "="*60,
            f"üìÅ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_files}",
            f"üìÅ –í—Å–µ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_moved}",
            ""
        ]
        
        for test_type, files in classified.items():
            report.append(f"üß™ {test_type.upper()}:")
            report.append(f"   –ù–∞–π–¥–µ–Ω–æ: {len(files)}")
            report.append(f"   –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ: {moved_count[test_type]}")
            
            if files:
                report.append("   –§–∞–π–ª—ã:")
                for file_path, confidence in sorted(files, key=lambda x: x[1], reverse=True):
                    status = "‚úÖ" if confidence >= 0.1 else "‚ö†Ô∏è"
                    report.append(f"     {status} {file_path.name} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
            report.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.extend([
            "üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:",
            "1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–º–ø–æ—Ä—Ç—ã –≤ –ø–µ—Ä–µ–º–µ—â–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö",
            "2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏",
            "3. –û–±–Ω–æ–≤–∏—Ç–µ CI/CD –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ",
            "4. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
        ])
        
        return "\n".join(report)

def check_existing_structure():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ—Å—Ç–æ–≤"""
    tests_dir = Path("tests")
    
    if not tests_dir.exists():
        print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è tests/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return False
    
    existing_dirs = [d.name for d in tests_dir.iterdir() if d.is_dir()]
    expected_dirs = ['unit', 'integration', 'e2e', 'smoke']
    
    print(f"üìÅ –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {existing_dirs}")
    print(f"üìÅ –û–∂–∏–¥–∞–µ–º—ã–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {expected_dirs}")
    
    return True

def update_pytest_config():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç pytest –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
    config_content = """[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --verbose
    --tb=short
    --strict-markers
    --disable-warnings
    --cov=app
    --cov=domain
    --cov-report=term-missing
    --cov-report=html:htmlcov
markers =
    unit: Unit tests (isolated logic, mocked dependencies)
    integration: Integration tests (database, external APIs)
    e2e: End-to-end tests (full user scenarios)
    smoke: Smoke tests (basic health checks)
    slow: Tests that take more than 1 second
    asyncio: Async tests
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
"""
    
    config_file = Path("pytest.ini")
    config_file.write_text(config_content)
    print("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω pytest.ini")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤")
    parser.add_argument('--dry-run', action='store_true', help='–†–µ–∂–∏–º —Å–∏–º—É–ª—è—Ü–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π')
    parser.add_argument('--min-confidence', type=float, default=0.1, 
                       help='–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è —Ñ–∞–π–ª–∞')
    parser.add_argument('--update-config', action='store_true', 
                       help='–û–±–Ω–æ–≤–∏—Ç—å pytest –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é')
    
    args = parser.parse_args()
    
    print("üß™ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ò –†–ï–û–†–ì–ê–ù–ò–ó–ê–¶–ò–Ø –¢–ï–°–¢–û–í")
    print("=" * 50)
    
    if not check_existing_structure():
        return 1
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    classifier = TestClassifier()
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    classifier.create_directories()
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ç–µ—Å—Ç—ã
    classified = classifier.classify_all_tests()
    
    if not any(classified.values()):
        print("‚ÑπÔ∏è  –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è")
        return 0
    
    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ç–µ—Å—Ç—ã
    moved_count = classifier.move_tests(classified, args.min_confidence, args.dry_run)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –µ—Å–ª–∏ –Ω–µ dry-run
    if not args.dry_run and moved_count:
        moved_files = {
            test_type: [fp.name for fp, conf in files if conf >= args.min_confidence]
            for test_type, files in classified.items()
        }
        classifier.update_imports_in_moved_tests(moved_files)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é pytest
    if args.update_config:
        update_pytest_config()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report = classifier.generate_summary_report(classified, moved_count)
    print(report)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    if not args.dry_run:
        report_file = Path("tests/classification_report.txt")
        report_file.write_text(report)
        print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_file}")
    
    return 0

if __name__ == "__main__":
    exit(main()) 