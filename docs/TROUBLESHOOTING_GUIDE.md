# üîß AI Assistant - Troubleshooting Guide

**–í–µ—Ä—Å–∏—è:** 2.0 | **–î–∞—Ç–∞:** –Ø–Ω–≤–∞—Ä—å 2025 | **–°—Ç–∞—Ç—É—Å:** –ê–∫—Ç—É–∞–ª—å–Ω—ã–π

---

## üö® –ë—ã—Å—Ç—Ä–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

### System Health Check
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π
make system-health

# –ò–ª–∏ –≤—Ä—É—á–Ω—É—é:
curl http://localhost:8000/health | jq .
curl http://localhost:3000/health | jq .
docker ps | grep ai-assistant
```

### Common Quick Fixes
```bash
# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã
make restart

# –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞
make cache-clear

# –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
make reindex

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤
make logs-tail
```

---

## üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã

### Backend API Issues

**–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è API:**
```bash
# Health check
curl -v http://localhost:8000/health

# Detailed health
curl http://localhost:8000/health/detailed | jq .

# Metrics
curl http://localhost:8000/metrics | grep -E "(request|error|latency)"

# OpenAPI schema
curl http://localhost:8000/openapi.json | jq .info
```

**Database connectivity:**
```bash
# PostgreSQL connection
pg_isready -h localhost -p 5432 -U ai_user

# Connection test —á–µ—Ä–µ–∑ Python
python -c "
import asyncpg
import asyncio
async def test():
    conn = await asyncpg.connect('postgresql://ai_user:password@localhost/ai_assistant')
    result = await conn.fetchval('SELECT 1')
    print(f'DB connection: {result}')
    await conn.close()
asyncio.run(test())
"

# Active connections
docker exec -it ai-assistant-postgres psql -U ai_user -d ai_assistant -c "
SELECT count(*) as active_connections FROM pg_stat_activity;
"
```

**Vector Database (Qdrant):**
```bash
# Qdrant health
curl http://localhost:6333/health | jq .

# Collections status
curl http://localhost:6333/collections | jq .

# Collection info
curl http://localhost:6333/collections/ai_documents | jq .

# Count points
curl http://localhost:6333/collections/ai_documents/points/count | jq .
```

### Frontend Issues

**Build and dev server:**
```bash
cd frontend

# Clear cache and reinstall
rm -rf node_modules package-lock.json
npm cache clean --force
npm install

# Development server
npm run dev

# Build issues
npm run build 2>&1 | tee build.log

# Type checking
npm run type-check
```

**Browser console errors:**
```bash
# Check console for errors in browser
# F12 -> Console tab

# Common fixes:
# 1. Clear browser cache (Ctrl+Shift+R)
# 2. Disable ad blockers
# 3. Check network tab for failed requests
```

---

## üêõ –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

### Problem 1: API returns 500 errors

**–°–∏–º–ø—Ç–æ–º—ã:**
- –í—Å–µ API –∑–∞–ø—Ä–æ—Å—ã –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç 500
- Health check fails
- –õ–æ–≥–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç Database connection errors

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:**
```bash
# 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏ API
docker logs ai-assistant-backend -f

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
docker exec -it ai-assistant-postgres pg_isready

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
docker exec -it ai-assistant-backend env | grep DATABASE_URL
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# 1. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –ë–î
docker restart ai-assistant-postgres

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ä–æ–ª–∏ –≤ .env
grep DATABASE_URL .env

# 3. –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ë–î –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
make db-reset
```

### Problem 2: Search returns no results

**–°–∏–º–ø—Ç–æ–º—ã:**
- –ü–æ–∏—Å–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- –î–∞–∂–µ —Ç–æ—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç
- Qdrant –¥–æ—Å—Ç—É–ø–µ–Ω

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:**
```bash
# 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
curl http://localhost:6333/collections/ai_documents/points/count

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å embedding service
curl -X POST http://localhost:8000/api/v1/test/embedding \
  -H "Content-Type: application/json" \
  -d '{"text": "test query"}'

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏ –ø–æ–∏—Å–∫–∞
docker logs ai-assistant-backend | grep -i search
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# 1. –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã
curl -X POST http://localhost:8000/api/v1/admin/reindex

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
curl http://localhost:6333/collections/ai_documents

# 3. –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
curl -X DELETE http://localhost:6333/collections/ai_documents
curl -X POST http://localhost:8000/api/v1/admin/initialize
```

### Problem 3: High memory usage

**–°–∏–º–ø—Ç–æ–º—ã:**
- Docker containers –ø–æ—Ç—Ä–µ–±–ª—è—é—Ç >8GB RAM
- System —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –º–µ–¥–ª–µ–Ω–Ω–æ–π
- OOM kills –≤ –ª–æ–≥–∞—Ö

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:**
```bash
# 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
docker stats

# 2. Memory profiling –¥–ª—è backend
docker exec -it ai-assistant-backend python -c "
import psutil
process = psutil.Process()
print(f'Memory: {process.memory_info().rss / 1024 / 1024:.2f} MB')
"

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫—ç—à Redis
docker exec -it ai-assistant-redis redis-cli info memory
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# 1. –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à
docker exec -it ai-assistant-redis redis-cli FLUSHALL

# 2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å memory limits –≤ docker-compose
services:
  backend:
    deploy:
      resources:
        limits:
          memory: 2G

# 3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
docker-compose down && docker-compose up -d
```

### Problem 4: Slow API responses

**–°–∏–º–ø—Ç–æ–º—ã:**
- API responses >5 seconds
- Timeouts –≤ frontend
- –í—ã—Å–æ–∫–∏–π CPU usage

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:**
```bash
# 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
curl http://localhost:8000/metrics | grep request_duration

# 2. Database query analysis
docker exec -it ai-assistant-postgres psql -U ai_user -d ai_assistant -c "
SELECT query, mean_exec_time, calls 
FROM pg_stat_statements 
ORDER BY mean_exec_time DESC 
LIMIT 10;
"

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å connection pool
docker logs ai-assistant-backend | grep -i "connection\|pool"
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# 1. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å database connections
# –í .env —É–≤–µ–ª–∏—á–∏—Ç—å pool size
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30

# 2. –î–æ–±–∞–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
docker exec -it ai-assistant-postgres psql -U ai_user -d ai_assistant -c "
CREATE INDEX CONCURRENTLY idx_documents_created_at ON documents(created_at);
"

# 3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Redis caching
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å hit rate
docker exec -it ai-assistant-redis redis-cli info stats | grep hit
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–ª–µ—Ä—Ç—ã

### Grafana Dashboards

**–î–æ—Å—Ç—É–ø –∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥—É:**
```bash
# Grafana
open http://localhost:3001
# Login: admin / admin

# Prometheus
open http://localhost:9090

# Key metrics to watch:
# - API response time (95th percentile < 2s)
# - Error rate (< 1%)
# - Memory usage (< 80%)
# - Database connections (< 80% of pool)
```

### Setting up alerts

**Prometheus alerts config:**
```yaml
# prometheus/rules/alerts.yml
groups:
  - name: ai-assistant
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 2m
        annotations:
          summary: "High error rate detected"
          
      - alert: SlowResponses
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 5
        for: 5m
        annotations:
          summary: "Slow API responses"
```

---

## üîß Performance Optimization

### Database Tuning

**PostgreSQL optimization:**
```sql
-- Check slow queries
SELECT query, mean_exec_time, calls, total_exec_time 
FROM pg_stat_statements 
WHERE mean_exec_time > 1000  -- queries slower than 1s
ORDER BY mean_exec_time DESC;

-- Add missing indexes
CREATE INDEX CONCURRENTLY idx_documents_vector_search 
ON documents USING gin(to_tsvector('english', content));

-- Analyze and vacuum
ANALYZE documents;
VACUUM ANALYZE documents;
```

**Connection pooling:**
```python
# app/database/session.py
from sqlalchemy.ext.asyncio import create_async_engine

engine = create_async_engine(
    DATABASE_URL,
    echo=False,
    pool_size=20,        # –£–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è –≤—ã—Å–æ–∫–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
    max_overflow=30,     # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    pool_pre_ping=True,  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
    pool_recycle=3600,   # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞–∂–¥—ã–π —á–∞—Å
)
```

### Vector Search Optimization

**Qdrant optimization:**
```bash
# Optimize collection parameters
curl -X PUT http://localhost:6333/collections/ai_documents \
-H "Content-Type: application/json" \
-d '{
  "optimizers_config": {
    "default_segment_number": 2,
    "max_segment_size": 20000,
    "memmap_threshold": 20000
  },
  "hnsw_config": {
    "m": 16,
    "ef_construct": 200
  }
}'

# Create payload index for filtering
curl -X PUT http://localhost:6333/collections/ai_documents/index \
-H "Content-Type: application/json" \
-d '{
  "field_name": "source_type",
  "field_schema": "keyword"
}'
```

---

## üîê Security Issues

### SSL/TLS Problems

**Certificate issues:**
```bash
# Check certificate
openssl s_client -connect your-domain.com:443 -servername your-domain.com

# Certificate expiry
openssl x509 -in cert.pem -text -noout | grep "Not After"

# Let's Encrypt renewal
certbot renew --dry-run
```

### Authentication Issues

**JWT token problems:**
```bash
# Decode JWT token
echo "your.jwt.token" | base64 -d

# Check token expiry
python -c "
import jwt
token = 'your.jwt.token'
decoded = jwt.decode(token, options={'verify_signature': False})
print(f'Expires: {decoded.get(\"exp\")}')
"

# Reset JWT secret
# Generate new secret and restart API
openssl rand -hex 32
```

---

## üìã Diagnostic Checklists

### Before Production Deployment
- [ ] All health checks pass
- [ ] Database migrations applied
- [ ] SSL certificates valid
- [ ] Monitoring configured
- [ ] Backup procedures tested
- [ ] Load testing completed
- [ ] Security scan passed

### During Incident Response
- [ ] Check system health dashboard
- [ ] Review recent deployments
- [ ] Check external service status
- [ ] Examine error logs
- [ ] Verify database connectivity
- [ ] Test API endpoints manually
- [ ] Check resource usage (CPU/Memory/Disk)

### Post-Incident
- [ ] Root cause identified
- [ ] Fix implemented and tested
- [ ] Monitoring alerts updated
- [ ] Documentation updated
- [ ] Team retrospective scheduled

---

## üìû Emergency Contacts

### On-Call Escalation
```
Level 1: DevOps Engineer
- Slack: @oncall-devops
- Phone: +7-XXX-XXX-XXXX

Level 2: Senior SRE  
- Slack: @oncall-sre
- Phone: +7-XXX-XXX-XXXX

Level 3: Engineering Manager
- Email: eng-manager@company.com
- Phone: +7-XXX-XXX-XXXX
```

### Service Dependencies
```bash
# External service status pages:
echo "OpenAI: https://status.openai.com/"
echo "Anthropic: https://status.anthropic.com/"
echo "GitHub: https://www.githubstatus.com/"
echo "Docker Hub: https://status.docker.com/"

# Internal dependencies:
curl http://internal-service.company.com/health
```

---

**Quick Reference:**
- üÜò Emergency shutdown: `make emergency-stop`
- üîÑ Quick restart: `make restart`  
- üìä System status: `make status`
- üìã Full health check: `make health-check`
- üßπ Clean everything: `make clean-all` 